{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LANfactory` package is a light-weight convenience package for training `likelihood approximation networks` (LANs) in torch (or keras), \n",
    "starting from supplied training data.\n",
    "\n",
    "[LANs](https://elifesciences.org/articles/65074), although more general in potential scope of applications, were conceived in the context of sequential sampling modeling\n",
    "to account for cognitive processes giving rise to *choice* and *reaction time* data in *n-alternative forced choice experiments* commonly encountered in the cognitive sciences.\n",
    "\n",
    "In this quick tutorial we will use the [`ssms`](https://github.com/AlexanderFengler/ssm_simulators) package to generate our training data using such a sequential sampling model (SSM). The use is in no way bound to utilize the `ssms` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install\n",
    "\n",
    "To install the `ssms` package type,\n",
    "\n",
    "`pip install git+https://github.com/AlexanderFengler/ssm_simulators`\n",
    "\n",
    "To install the `LANfactory` package type,\n",
    "\n",
    "`pip install git+https://github.com/AlexanderFengler/LANfactory`\n",
    "\n",
    "Necessary dependency should be installed automatically in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "import ssms\n",
    "import lanfactory \n",
    "import os\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Training Data\n",
    "First we need to generate some training data. As mentioned above we will do so using the `ssms` python package, however without delving into a detailed explanation\n",
    "of this package. Please refer to the [basic ssms tutorial] (https://github.com/AlexanderFengler/ssm_simulators) in case you want to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make configs\n",
    "\n",
    "# Initialize the generator config (for MLP LANs)\n",
    "generator_config = deepcopy(ssms.config.data_generator_config['lan']['mlp'])\n",
    "# Specify generative model (one from the list of included models mentioned above)\n",
    "generator_config['dgp_list'] = 'angle' \n",
    "# Specify number of parameter sets to simulate\n",
    "generator_config['n_parameter_sets'] = 100 \n",
    "# Specify how many samples a simulation run should entail\n",
    "generator_config['n_samples'] = 1000\n",
    "# Specify folder in which to save generated data\n",
    "generator_config['output_folder'] = 'data/lan_mlp/'\n",
    "\n",
    "# Make model config dict\n",
    "model_config = ssms.config.model_config['angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking:  data/lan_mlp/\n",
      "simulation round: 1  of 10\n",
      "simulation round: 2  of 10\n",
      "simulation round: 3  of 10\n",
      "simulation round: 4  of 10\n",
      "simulation round: 5  of 10\n",
      "simulation round: 6  of 10\n",
      "simulation round: 7  of 10\n",
      "simulation round: 8  of 10\n",
      "simulation round: 9  of 10\n",
      "simulation round: 10  of 10\n",
      "Writing to file:  data/lan_mlp/training_data_0_nbins_0_n_1000/angle/training_data_angle_18ef3b40b6e611ecbc37acde48001122.pickle\n"
     ]
    }
   ],
   "source": [
    "# MAKE DATA\n",
    "\n",
    "my_dataset_generator = ssms.dataset_generators.data_generator(generator_config = generator_config,\n",
    "                                                              model_config = model_config)\n",
    "\n",
    "training_data = my_dataset_generator.generate_data_training_uniform(save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE DATALOADERS\n",
    "\n",
    "# List of datafiles (here only one)\n",
    "folder_ = 'data/lan_mlp/training_data_0_nbins_0_n_1000/angle/'\n",
    "file_list_ = [folder_ + file_ for file_ in os.listdir(folder_)]\n",
    "\n",
    "# Training dataset\n",
    "torch_training_dataset = lanfactory.trainers.DatasetTorch(file_IDs = file_list_,\n",
    "                                                          batch_size = 128)\n",
    "\n",
    "torch_training_dataloader = torch.utils.data.DataLoader(torch_training_dataset,\n",
    "                                                         shuffle = True,\n",
    "                                                         batch_size = None,\n",
    "                                                         num_workers = 1,\n",
    "                                                         pin_memory = True)\n",
    "\n",
    "# Validation dataset\n",
    "torch_validation_dataset = lanfactory.trainers.DatasetTorch(file_IDs = file_list_,\n",
    "                                                          batch_size = 128)\n",
    "\n",
    "torch_validation_dataloader = torch.utils.data.DataLoader(torch_validation_dataset,\n",
    "                                                          shuffle = True,\n",
    "                                                          batch_size = None,\n",
    "                                                          num_workers = 1,\n",
    "                                                          pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network config: \n",
      "{'layer_types': ['dense', 'dense', 'dense'], 'layer_sizes': [100, 100, 1], 'activations': ['tanh', 'tanh', 'linear'], 'loss': ['huber'], 'callbacks': ['checkpoint', 'earlystopping', 'reducelr']}\n",
      "Train config: \n",
      "{'batch_size': 128, 'n_epochs': 100, 'optimizer': 'adam', 'learning_rate': 0.002, 'loss': 'huber', 'metrics': [<keras.losses.MeanSquaredError object at 0x12aecdc70>, <keras.losses.Huber object at 0x12ac93820>], 'callbacks': ['checkpoint', 'earlystopping', 'reducelr']}\n"
     ]
    }
   ],
   "source": [
    "# SPECIFY NETWORK CONFIGS AND TRAINING CONFIGS\n",
    "\n",
    "network_config = lanfactory.config.network_configs.network_config_mlp\n",
    "\n",
    "print('Network config: ')\n",
    "print(network_config)\n",
    "\n",
    "train_config = lanfactory.config.network_configs.train_config_mlp\n",
    "\n",
    "print('Train config: ')\n",
    "print(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh\n",
      "linear\n"
     ]
    }
   ],
   "source": [
    "# LOAD NETWORK\n",
    "net = lanfactory.trainers.TorchMLP(network_config = deepcopy(network_config),\n",
    "                                   input_shape = torch_training_dataset.input_dim,\n",
    "                                   save_folder = '/data/torch_models/',\n",
    "                                   generative_model_id = 'angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folder:  data\n",
      "Moving on...\n",
      "Did not find folder:  data/torch_models\n",
      "Creating it...\n",
      "Did not find folder:  data/torch_models/angle\n",
      "Creating it...\n",
      "Saved network config\n",
      "Saved train config\n"
     ]
    }
   ],
   "source": [
    "# SAVE CONFIGS\n",
    "lanfactory.utils.save_configs(model_id = net.model_id + '_torch_',\n",
    "                                  save_folder = 'data/torch_models/angle/', \n",
    "                                  network_config = network_config, \n",
    "                                  train_config = train_config, \n",
    "                                  allow_abs_path_folder_generation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device:  cpu\n",
      "Found folder:  data\n",
      "Moving on...\n",
      "Found folder:  data/torch_models\n",
      "Moving on...\n",
      "Found folder:  data/torch_models/angle\n",
      "Moving on...\n"
     ]
    }
   ],
   "source": [
    "# LOAD MODEL TRAINER\n",
    "model_trainer = lanfactory.trainers.ModelTrainerTorchMLP(train_config = deepcopy(train_config),\n",
    "                                                            data_loader_train = torch_training_dataloader,\n",
    "                                                            data_loader_valid = torch_validation_dataloader,\n",
    "                                                            model = net,\n",
    "                                                            output_folder = 'data/torch_models/',\n",
    "                                                            warm_start = False,\n",
    "                                                            allow_abs_path_folder_generation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 / 100, batch: 0 / 1562, batch_loss: 0.2204161137342453\n",
      "epoch: 0 / 100, batch: 1000 / 1562, batch_loss: 0.15364894270896912\n",
      "Epoch took 11.396775960922241 seconds\n",
      "STARTING VALIDATION:\n",
      "epoch 0 / 100, validation_loss: 0.1417\n",
      "epoch: 1 / 100, batch: 0 / 1562, batch_loss: 0.14299717545509338\n",
      "epoch: 1 / 100, batch: 1000 / 1562, batch_loss: 0.11169125884771347\n",
      "Epoch took 11.024933815002441 seconds\n",
      "STARTING VALIDATION:\n",
      "epoch 1 / 100, validation_loss: 0.1234\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/afengler/OneDrive/project_lanfactory/LANfactory/basic_tutorial.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/afengler/OneDrive/project_lanfactory/LANfactory/basic_tutorial.ipynb#ch0000018?line=0'>1</a>\u001b[0m \u001b[39m# TRAIN MODEL\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/afengler/OneDrive/project_lanfactory/LANfactory/basic_tutorial.ipynb#ch0000018?line=1'>2</a>\u001b[0m model_trainer\u001b[39m.\u001b[39;49mtrain_model(save_history \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/afengler/OneDrive/project_lanfactory/LANfactory/basic_tutorial.ipynb#ch0000018?line=2'>3</a>\u001b[0m                           save_model \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/afengler/OneDrive/project_lanfactory/LANfactory/basic_tutorial.ipynb#ch0000018?line=3'>4</a>\u001b[0m                           verbose \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/OneDrive/project_lanfactory/LANfactory/lanfactory/trainers/torch_mlp.py:172\u001b[0m, in \u001b[0;36mModelTrainerTorchMLP.train_model\u001b[0;34m(self, save_history, save_model, verbose)\u001b[0m\n\u001b[1;32m    <a href='file:///~/OneDrive/project_lanfactory/LANfactory/lanfactory/trainers/torch_mlp.py?line=169'>170</a>\u001b[0m epoch_s_t \u001b[39m=\u001b[39m time()\n\u001b[1;32m    <a href='file:///~/OneDrive/project_lanfactory/LANfactory/lanfactory/trainers/torch_mlp.py?line=170'>171</a>\u001b[0m \u001b[39m#with tqdm.tqdm(self.data_loader_train , unit = 'batch') as tepoch:\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/OneDrive/project_lanfactory/LANfactory/lanfactory/trainers/torch_mlp.py?line=171'>172</a>\u001b[0m \u001b[39mfor\u001b[39;00m xb, yb \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_loader_train:\n\u001b[1;32m    <a href='file:///~/OneDrive/project_lanfactory/LANfactory/lanfactory/trainers/torch_mlp.py?line=172'>173</a>\u001b[0m     \u001b[39m#tepoch.set_description('Epoch {}'.format(epoch))\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/OneDrive/project_lanfactory/LANfactory/lanfactory/trainers/torch_mlp.py?line=173'>174</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpin_memory \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdev\u001b[39m.\u001b[39m\u001b[39m__str__\u001b[39m() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///~/OneDrive/project_lanfactory/LANfactory/lanfactory/trainers/torch_mlp.py?line=174'>175</a>\u001b[0m         xb, yb \u001b[39m=\u001b[39m xb\u001b[39m.\u001b[39mcuda(non_blocking \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m), yb\u001b[39m.\u001b[39mcuda(non_blocking \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1203'>1204</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1205'>1206</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1206'>1207</a>\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1207'>1208</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1208'>1209</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1209'>1210</a>\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1168'>1169</a>\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1169'>1170</a>\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1170'>1171</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1171'>1172</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1172'>1173</a>\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1173'>1174</a>\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1174'>1175</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=997'>998</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=998'>999</a>\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=999'>1000</a>\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1007'>1008</a>\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1008'>1009</a>\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1009'>1010</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1010'>1011</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1011'>1012</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1012'>1013</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1013'>1014</a>\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1014'>1015</a>\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/site-packages/torch/utils/data/dataloader.py?line=1015'>1016</a>\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/queues.py?line=104'>105</a>\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/queues.py?line=105'>106</a>\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/queues.py?line=106'>107</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/queues.py?line=107'>108</a>\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/queues.py?line=108'>109</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py?line=254'>255</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py?line=255'>256</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py?line=256'>257</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py?line=422'>423</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py?line=423'>424</a>\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py?line=424'>425</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py?line=927'>928</a>\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py?line=929'>930</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py?line=930'>931</a>\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py?line=931'>932</a>\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/multiprocessing/connection.py?line=932'>933</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/cssm/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/selectors.py?line=412'>413</a>\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/selectors.py?line=413'>414</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/selectors.py?line=414'>415</a>\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/selectors.py?line=415'>416</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/opt/miniconda3/envs/cssm/lib/python3.8/selectors.py?line=416'>417</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL\n",
    "model_trainer.train_model(save_history = True,\n",
    "                          save_model = True,\n",
    "                          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d453750a4b9695db121c052d9666dec5f9db6b84895d7d9e68c24a4cb27d149"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('ssms')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
